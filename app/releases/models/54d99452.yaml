---
## Pod Monitor
apiVersion: monitoring.coreos.com/v1
kind: PodMonitor
metadata:
  name: model-54d99452-monitor
  namespace: monitoring
spec:
  selector:
    matchLabels:
      seldon-deployment-id: model-54d99452
  podMetricsEndpoints:
    - port: "http"  # Match the container port name
      path: /metrics
  namespaceSelector:
    any: true
---
## Seldon Deployment
apiVersion: machinelearning.seldon.io/v1
kind: SeldonDeployment
metadata:
  name: model-54d99452
  namespace: models
  annotations:
    seldon.io/no-storage-initializer: "true"
    prometheus.io/scrape: "true"
    prometheus.io/path: "/metrics"
    prometheus.io/port: "9000"  # Updated to match new container port
spec:
  protocol: v2
  predictors:
    - name: predictor-54d99452
      replicas: 1
      graph:
        name: model-54d99452
        type: MODEL
        children: []
        implementation: 54D99452_SERVER
      svcOrchSpec:
        env:
          - name: LOG_LEVEL
            value: DEBUG
          - name: ROOT_PATH
            value: "/54d99452"
      componentSpecs:
        - spec:
            containers:
              - name: model-54d99452
                env:
                  - name: ROOT_PATH
                    value: "/54d99452"
                livenessProbe:
                  httpGet:
                    path: /v2/health/live
                    port: http  # Named port reference
                  initialDelaySeconds: 20
                  periodSeconds: 10
                readinessProbe:
                  httpGet:
                    path: /v2/health/ready
                    port: http  # Named port reference
                  initialDelaySeconds: 20
                  periodSeconds: 10
                ports:
                  - name: http  # Updated from "metrics" to "http"
                    containerPort: 9000
                    protocol: TCP
                resources:
                  requests:
                    memory: "512Mi"
                    cpu: "500m"
                    nvidia.com/gpu: "1"
                  limits:
                    memory: "20Gi"
                    cpu: "2"
                    nvidia.com/gpu: "1"
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: model-54d99452-docs-ingress
  namespace: models
  annotations:
    nginx.ingress.kubernetes.io/use-regex: "true"  # Enable regex matching
    nginx.ingress.kubernetes.io/rewrite-target: /54d99452/docs$2
    nginx.ingress.kubernetes.io/proxy-body-size: "50m"
    nginx.ingress.kubernetes.io/x-forwarded-prefix: /54d99452
spec:
  ingressClassName: nginx
  rules:
    - http:
        paths:
          # API Documentation Endpoint
          - path: /54d99452/docs(/|$)(.*)
            pathType: ImplementationSpecific
            backend:
              service:
                name: model-54d99452-predictor-54d99452-model-54d99452 # seldon-models-model-54d99452 ### model-54d99452-predictor-54d99452-model-54d99452
                port:
                  number: 9000
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: model-54d99452-api-ingress
  namespace: models
  annotations:
    nginx.ingress.kubernetes.io/use-regex: "true"  # Enable regex matching
    nginx.ingress.kubernetes.io/rewrite-target: /54d99452/v2/models/$1/infer
    nginx.ingress.kubernetes.io/proxy-body-size: "50m"
spec:
  ingressClassName: nginx
  rules:
    - http:
        paths:
          # Prediction Endpoint
          - path: /54d99452(/|$)(.*)
            pathType: ImplementationSpecific
            backend:
              service:
                name: model-54d99452-predictor-54d99452-model-54d99452  # seldon-models-model-54d99452 ### model-54d99452-predictor-54d99452-model-54d99452
                port:
                  number: 9000